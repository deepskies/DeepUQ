
\documentclass[twocolumn]{aastex631}

% Import showyourwork magic
\usepackage{showyourwork}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{unicode-math}


% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{multirow}

% hyperref makes hyperlinks in the resulting PDF.
% xurl can wrap the link if it spans a column (especially in citations).
\usepackage{hyperref}
\usepackage{xurl}


% This command creates a new command \editor{} that highlights any of the text in {} with a maroon color, so it can easily be spotted during internal review

\usepackage[textsize=tiny]{todonotes}
\newcommand{\editor}[1]{{\color{purple} #1}}

\begin{document}

\title{DeepUQ} % Define the title itself, so it may be used in headers

\author{Author 1 \thanks{Becky Nevin, rnevin@fnal.gov}}


\begin{abstract}
    This project aims to create a framework for calibrating uncertainty expectations in various ML and statistical models.
    It builds on DeepBench's pendulum module, controlling error injection, calculating an analytic expectation for the error impact on the final confidence intervals, and comparing this expectation to that produced by various uncertainty-aware ML and statistical techniques.
    Here, we pursue the following modeling techniques: hierarchical and non-hierarchical Hamiltonian Monte Carlo sampling (\texttt{numpyro}), hierarchical and non-hierarchical simulation-based inference (\texttt{mackelab}), and deep ensembles.
    We inject aleatoric error on the pendulum parameters individually ($L$, $\theta_0$, and $a_g$) at a variety of levels (1\%, 10\%, and 50\%).
    We compare this to expectations of aleatoric and epistemic error from the various ML techniques and explore the bias and confidence of the models compared to our analytic expectation.
\end{abstract}

\section{Introduction}
Cite other UQ techniques, mostly Caldeira \& Nord.

\subsection{Error injection, (post-hoc) calibration, reliability}
Historically, aleatoric uncertainty is represented as $\epsilon$ in linear regression.
It is an additive uncertainty, not necessarily associated with a certain parameter.
This type of uncertainty can be homoskedastic or heteroskedastic.
If $\epsilon$ is a multiplicative term modifying an input parameter, the uncertainty is considered to be heteroskedastic, since it is tied to the parameter value.
In a linear regression setting, epistemic uncertainty is accounted for by the error on the $\beta$, or slope coefficient (\citealt{Nagl2022}).

Many methods focus on creating software that will produce an uncertainty prediction.
However, a critical missed step is to calibrate this uncertainty prediction, testing its reliability against an expectation.
Several authors have investigated this, focusing on the calibration of classification problems, including Guao et al. 2017, Wegner et al. 2020, and Zhang et al. 2020.

\begin{itemize}
    \item Guo et al. 2017; this is the paper that presents temperature scaling as a method to quantify calibration of deep neural networks.
    They also find that while neural networks today are more accurate than they were a decade ago, they are no longer well-calibrated, meaning that the confidence is substantially higher than accuracy.
    So here, we are comparing confidence, which is a measurement of probabilities associate with the predicted labels, with the accuracy, both of which you get from the output.
    So they are not propagating an error expecation to; they are instead comparing output to output. 
    \item Wegner et al. 2020
    \item Zhang et al. 2020.
\end{itemize}

To read:
\begin{itemize}
    \item Ghanem et al. 2017 is a handbook on UQ
\end{itemize}

\section{Methods}
\subsection{Uncertainty definition and injection}
\subsection{Modeling techniques}
\subsubsection{HMC Sampling}
\subsubsection{SBI}
\subsubsection{DE}

\section{Analysis}
\subsection{}


%\editor{Here is an quick comment that may appear, indicating an addition by an editor.}


%\subsubsection{Equations}

%Large equations should be numbered and included in an equation block such that
%\begin{align}
%    E=mc^2 \label{eq:1} \\
%    F=ma \label{eq:2}
%\end{align}


\section {Acknowledgements}

Make sure to cite \cite{harris2020array} all of your sources \cite{Hunter:2007}.


You can also optionally provide contributions by person:

\paragraph{Becky Nevin}
Author 1 contributed X Y and Z

\paragraph{Author 2}
Author 2 contributed A B and C

If you work with the DeepSkies research group; please include the following text:

\emph{We acknowledge the Deep Skies Lab as a community of multi-domain experts and collaborators whoâ€™ve facilitated an environment of open discussion, idea-generation, and collaboration. This community was important for the development of this project.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Style of the bib may change based on the publications requirements

\bibliography{bib}


 % Ending the multicol format before the appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Appendix}


% Todo Example of running show your work function within the tex to produce table

\subsection{Table References}

% Todo: Show your work table drawing results from a function

\end{document}