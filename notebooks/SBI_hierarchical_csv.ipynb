{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f774193d",
   "metadata": {},
   "source": [
    "# Hierarchical pendulum SBI, using a csv of (theta, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe040c0f",
   "metadata": {},
   "source": [
    "## The dataset: simple static pendulum\n",
    "Using the position of a pendulum at one point in time from a collection of pendulums on two different planets, determine the position associated with L, $\\theta$, and $a_g$ using a deep ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8c8f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, import all the necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#from src.scripts import utils\n",
    "import numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a76432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.01\n"
     ]
    }
   ],
   "source": [
    "import deepbench\n",
    "from deepbench.physics_object import Pendulum\n",
    "print(deepbench.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bfe9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi import utils, inference, analysis\n",
    "# from sbi import inference\n",
    "from sbi.inference import SNPE, simulate_for_sbi, prepare_for_sbi\n",
    "from sbi.inference.base import infer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478548e",
   "metadata": {},
   "source": [
    "## Prepare dataframe that associates (theta, x)\n",
    "Here, I run a quick simulation that grid-searches all the theta values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff66af4-8bf4-4019-8c1a-8f0ef4428137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_thetas_and_xs_single(thetas_in, rng_key):\n",
    "    # except length will have 8 elements as will theta\n",
    "    length, theta, μ_a_g, σ_a_g = thetas_in\n",
    "\n",
    "    a_g = rs.normal(loc=μ_a_g, scale=σ_a_g)\n",
    "    #numpyro.sample(\"a_g\", numpyro.distributions.TruncatedNormal(float(μ_a_g), float(σ_a_g), low = 0.01))\n",
    "    #rng_key = jax.random.PRNGKey(1)  # You can use any valid random key\n",
    "    #a_g_1 = numpyro.sample(\"a_g\", numpyro.distributions.TruncatedNormal(float(μ_a_g), float(σ_a_g), low = 0.01), rng_key = rng_key)\n",
    "\n",
    "    #a_g = [a_g_0, a_g_1]\n",
    "    #print('a_g', a_g)\n",
    "    \n",
    "    \n",
    "    pendulum = Pendulum(\n",
    "                pendulum_arm_length=float(length),\n",
    "                starting_angle_radians=float(theta),\n",
    "                acceleration_due_to_gravity=float(a_g),\n",
    "                noise_std_percent={\n",
    "                    \"pendulum_arm_length\": 0.0,\n",
    "                    \"starting_angle_radians\": 0.1,\n",
    "                    \"acceleration_due_to_gravity\": 0.0,\n",
    "                },\n",
    "            )\n",
    "    x = pendulum.create_object(0.75, noiseless=False)\n",
    "    del pendulum\n",
    "    return a_g, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37caacc2-d7ea-407e-9583-f94643976037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "from numpyro.util import enable_x64\n",
    "\n",
    "enable_x64()\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "rng_key = jax.random.PRNGKey(0)\n",
    "print(rng_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5e4866-6cf1-40b9-93db-303988cbf8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set priors for all of these things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7baa131-951c-4a69-a7c9-6f433afe6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay now make a dataframe with a bunch of different options for the parameters\n",
    "# generate the L, theta, a_g values somewhat randomly between ranges\n",
    "length_percent_error_all = 0.0\n",
    "theta_percent_error_all = 0.1\n",
    "a_g_percent_error_all = 0.0\n",
    "pos_err = 0.0\n",
    "\n",
    "time = 0.75\n",
    "\n",
    "length_df = 100\n",
    "thetas = np.zeros((length_df, 5))\n",
    "xs = np.zeros((length_df))\n",
    "#labels = np.zeros((2*length_df, 2))\n",
    "#error = []\n",
    "#y_noisy = []\n",
    "\n",
    "for r in range(length_df):\n",
    "    \n",
    "    rs = np.random.RandomState()#2147483648)# \n",
    "    \n",
    "    \n",
    "    length = abs(rs.normal(loc=5, scale=2))\n",
    "    theta = abs(rs.normal(loc=jnp.pi/100, scale=jnp.pi/500))\n",
    "    #length, theta, μ_a_g, σ_a_g = thetas_in\n",
    "    μ_a_g = abs(rs.normal(loc=10, scale=2))\n",
    "    σ_a_g = abs(rs.normal(loc=1, scale=0.5))\n",
    "    \n",
    "\n",
    "    thetas_in = [length, theta, μ_a_g, σ_a_g]\n",
    "\n",
    "    a_g, x = save_thetas_and_xs_single(thetas_in, rs)\n",
    "        \n",
    "    \n",
    "    thetas[r,:] = [length, theta, a_g, μ_a_g, σ_a_g]\n",
    "    xs[r] = x\n",
    "    #labels[r,:] = [0, r]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "057847da-d355-49d1-99e9-ef64173776fb",
   "metadata": {},
   "source": [
    "# make a df\n",
    "data_params = {\n",
    "    'length': xs[:,0],\n",
    "    'theta': xs[:,1],\n",
    "    'a_g': xs[:,2],\n",
    "    'planet_id': labels[:,0],\n",
    "    'pendulum_id': labels[:,1],\n",
    "    'pos_err': error,\n",
    "    \n",
    "}\n",
    "\n",
    "## create the DataFrame\n",
    "df = pd.DataFrame(data_params)\n",
    "df['pos'] = y_noisy\n",
    "df['time'] = np.repeat(time,2*length_df)\n",
    "\n",
    "pend_encoder = LabelEncoder()\n",
    "df[\"pend_code\"] = pend_encoder.fit_transform(df[\"pendulum_id\"].values)\n",
    "planet_encoder = LabelEncoder()\n",
    "df[\"planet_code\"] = planet_encoder.fit_transform(df[\"planet_id\"].values)\n",
    "\n",
    "planet_code = df[\"planet_code\"].values\n",
    "pend_obs = df[\"pos\"].values\n",
    "times = df[\"time\"].values\n",
    "pend_code = df[\"pend_code\"].values\n",
    "\n",
    "df = df[[\"length\",\"theta\",\"a_g\",\"pos\",\"pos_err\",\"pend_code\",\"planet_code\",\"time\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e7b4a-afb2-412e-891c-71a2a988c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there a way to do an easier embedding network?\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SummaryNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Summary Network module\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2D convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding='same')\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same')\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.conv6 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same')\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Maxpool layer that reduces 32x32 image to 4x4\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # out_features correspond to 4*(Number of summary parameters)\n",
    "        self.fc = nn.Linear(in_features=128 * 4 * 4, out_features=48)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 32, 32)\n",
    "\n",
    "        x = (self.bn1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bn2(F.relu(self.conv2(x))))\n",
    "\n",
    "        x = self.bn3(F.relu(self.conv3(x)))\n",
    "        x = self.pool(self.bn4(F.relu(self.conv4(x))))\n",
    "\n",
    "        x = self.bn5(F.relu(self.conv5(x)))\n",
    "        x = self.pool(self.bn6(F.relu(self.conv6(x))))\n",
    "\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f41fc285-883e-4313-bae2-e8e1c10a3e5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Simulated data must be a batch with at least two dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m inference \u001b[38;5;241m=\u001b[39m SNPE(prior\u001b[38;5;241m=\u001b[39mprior, density_estimator\u001b[38;5;241m=\u001b[39mneural_posterior, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Now that we have both the simulated images and parameters defined properly, we can train the SBI.\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m density_estimator \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_simulations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m posterior \u001b[38;5;241m=\u001b[39m inference\u001b[38;5;241m.\u001b[39mbuild_posterior(density_estimator)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deepuq-DRzT0TL8-py3.9/lib/python3.9/site-packages/sbi/inference/snpe/snpe_c.py:179\u001b[0m, in \u001b[0;36mSNPE_C.train\u001b[0;34m(self, num_atoms, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, use_combined_loss, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_non_atomic_loss:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;66;03m# Take care of z-scoring, pre-compute and store prior terms.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_state_for_mog_proposal()\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deepuq-DRzT0TL8-py3.9/lib/python3.9/site-packages/sbi/inference/snpe/snpe_base.py:314\u001b[0m, in \u001b[0;36mPosteriorEstimator.train\u001b[0;34m(self, training_batch_size, learning_rate, validation_fraction, stop_after_epochs, max_num_epochs, clip_max_norm, calibration_kernel, resume_training, force_first_round_loss, discard_prior_samples, retrain_from_scratch, show_train_summary, dataloader_kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Use only training data for building the neural net (z-scoring transforms)\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neural_net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_neural_net(\n\u001b[1;32m    311\u001b[0m     theta[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_indices]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    312\u001b[0m     x[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_indices]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    313\u001b[0m )\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_shape \u001b[38;5;241m=\u001b[39m \u001b[43mx_shape_from_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m test_posterior_net_for_multi_d_x(\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neural_net,\n\u001b[1;32m    318\u001b[0m     theta\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    319\u001b[0m     x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m theta, x\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/deepuq-DRzT0TL8-py3.9/lib/python3.9/site-packages/sbi/utils/sbiutils.py:57\u001b[0m, in \u001b[0;36mx_shape_from_simulation\u001b[0;34m(batch_x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mx_shape_from_simulation\u001b[39m(batch_x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize:\n\u001b[1;32m     56\u001b[0m     ndims \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m ndims \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulated data must be a batch with at least two dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch_x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAssertionError\u001b[0m: Simulated data must be a batch with at least two dimensions."
     ]
    }
   ],
   "source": [
    "import sbi\n",
    "# Now let's put them in a tensor form that SBI can read.\n",
    "theta = torch.tensor(thetas,dtype=torch.float32)\n",
    "x = torch.tensor(xs,dtype=torch.float32)\n",
    "\n",
    "#embedding_net = SummaryNet()\n",
    "\n",
    "# instantiate the neural density estimator\n",
    "neural_posterior = sbi.utils.posterior_nn(model='maf')#,\n",
    "                                  #embedding_net=embedding_net,\n",
    "                                  #hidden_features=hidden_features,\n",
    "                                  #num_transforms=num_transforms)\n",
    "\n",
    "# make a fake prior\n",
    "# L, theta_0, a_g, mu, sigma\n",
    "\n",
    "'''\n",
    "length = abs(rs.normal(loc=5, scale=2))\n",
    "    theta = abs(rs.normal(loc=jnp.pi/100, scale=jnp.pi/500))\n",
    "    #length, theta, μ_a_g, σ_a_g = thetas_in\n",
    "    μ_a_g = abs(rs.normal(loc=10, scale=2))\n",
    "    σ_a_g = abs(rs.normal(loc=1, scale=0.5))\n",
    "'''\n",
    "prior_low = [0, jnp.pi / 1000, 0, 0, 0]\n",
    "prior_high = [10, jnp.pi / 10, 20, 20, 4]\n",
    "\n",
    "prior = utils.BoxUniform(low=torch.tensor(prior_low), high=torch.tensor(prior_high), device='cpu')\n",
    "\n",
    "# setup the inference procedure with the SNPE-C procedure\n",
    "inference = SNPE(prior=prior, density_estimator=neural_posterior, device=\"cpu\")\n",
    "\n",
    "# Now that we have both the simulated images and parameters defined properly, we can train the SBI.\n",
    "density_estimator = inference.append_simulations(theta,x).train()\n",
    "posterior = inference.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e3e53-df23-49ad-b7e7-0f558dcbaa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd590a4-d7eb-4752-8487-b5e33d1796b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4099a882-1a7f-4266-8a9a-57e289c4596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.58798179e+00  2.07597931e-02  1.57562023e+01  1.42910159e+01\n",
      "   1.84377293e+00  5.92555688e-02]\n",
      " [ 2.05339683e+00  2.85406868e-02  1.13419898e+01  1.20854526e+01\n",
      "   1.78660172e+00 -1.17401254e-02]\n",
      " [ 5.41048906e+00  3.10157844e-02  9.65805085e+00  9.77499190e+00\n",
      "   7.86417236e-01  8.40525588e-02]\n",
      " [ 5.89551163e+00  2.10998454e-02  7.37501978e+00  7.74171478e+00\n",
      "   5.68880503e-01  6.13586092e-02]\n",
      " [ 4.65010046e+00  2.59832434e-02  1.33441194e+01  1.06048101e+01\n",
      "   1.40196020e+00  3.87906924e-02]\n",
      " [ 3.63916820e+00  3.71920366e-02  6.93015253e+00  7.00727495e+00\n",
      "   4.96412826e-01  8.03115525e-02]\n",
      " [ 1.17014982e+00  2.43437293e-02  1.08487147e+01  8.74500622e+00\n",
      "   1.82928529e+00 -1.62962656e-02]\n",
      " [ 8.13093751e+00  2.26712859e-02  8.49684037e+00  9.61914095e+00\n",
      "   1.16070774e+00  1.57255549e-01]\n",
      " [ 7.81344622e+00  2.18606391e-02  8.66833626e+00  8.91278844e+00\n",
      "   7.60943405e-01  1.17466968e-01]\n",
      " [ 7.18380606e+00  2.93259361e-02  1.04340244e+01  1.10153835e+01\n",
      "   7.18935034e-01  1.23606278e-01]\n",
      " [ 8.66230907e+00  3.37805241e-02  9.04508070e+00  9.57798315e+00\n",
      "   1.10675373e+00  2.28827151e-01]\n",
      " [ 7.32107116e+00  2.90221476e-02  1.01573650e+01  1.04424255e+01\n",
      "   3.41867894e-01  1.48306349e-01]\n",
      " [ 3.95540386e+00  3.00933049e-02  8.67564694e+00  9.02089827e+00\n",
      "   1.58275194e+00  5.34929732e-02]\n",
      " [ 8.29917042e+00  2.66860758e-02  1.50548645e+01  1.35739188e+01\n",
      "   1.47935116e+00  1.09236524e-01]\n",
      " [ 6.54886385e+00  3.23551988e-02  9.91886544e+00  8.72048046e+00\n",
      "   1.46799988e+00  1.58799857e-01]\n",
      " [ 6.55417098e+00  2.85607569e-02  1.00626884e+01  1.06474709e+01\n",
      "   6.64052773e-01  9.92727143e-02]\n",
      " [ 4.64595106e+00  3.63073766e-02  9.58832164e+00  9.52154395e+00\n",
      "   1.16107148e-01  8.03468560e-02]\n",
      " [ 6.62535287e+00  3.62424297e-02  9.20186607e+00  1.01115727e+01\n",
      "   7.19773757e-01  1.37442009e-01]\n",
      " [ 3.86084615e+00  2.38472500e-02  1.15317590e+01  9.25626712e+00\n",
      "   1.98746798e+00  2.53124646e-02]\n",
      " [ 2.63615694e+00  2.92843933e-02  7.48050527e+00  8.73986926e+00\n",
      "   1.26731970e+00  2.15072004e-02]\n",
      " [ 9.24694028e+00  2.53866666e-02  8.71831775e+00  9.53121280e+00\n",
      "   1.26759688e+00  1.85703677e-01]\n",
      " [ 4.76277142e+00  2.50156389e-02  9.59923042e+00  1.05859708e+01\n",
      "   7.91321609e-01  5.77980528e-02]\n",
      " [ 3.33891208e+00  2.09129011e-02  1.01697692e+01  1.02200303e+01\n",
      "   9.61153021e-02  1.81344591e-02]\n",
      " [ 4.60125198e+00  3.29012386e-02  1.00066125e+01  1.14757895e+01\n",
      "   1.73861959e+00  6.04742040e-02]\n",
      " [ 3.69775311e+00  2.70038124e-02  9.92378764e+00  9.51126432e+00\n",
      "   1.10703438e+00  3.87942577e-02]\n",
      " [ 8.30443786e+00  2.97848318e-02  9.22440521e+00  7.85558816e+00\n",
      "   1.46955316e+00  1.84144688e-01]\n",
      " [ 6.14311280e+00  3.29384479e-02  8.75203494e+00  9.86271705e+00\n",
      "   7.54212569e-01  1.06892003e-01]\n",
      " [ 7.08821645e+00  3.08465422e-02  1.14506806e+01  1.13888238e+01\n",
      "   1.06294476e+00  1.27798728e-01]\n",
      " [ 4.76092735e+00  2.48468205e-02  9.50004690e+00  8.71944277e+00\n",
      "   1.09483345e+00  6.98537062e-02]\n",
      " [ 4.06859325e+00  3.22231476e-02  8.17837114e+00  8.20819248e+00\n",
      "   7.74513761e-01  5.63338410e-02]\n",
      " [ 5.53657362e+00  3.85990715e-02  9.27702669e+00  9.39797688e+00\n",
      "   7.44561328e-01  1.08692946e-01]\n",
      " [ 4.54024978e+00  3.10398448e-02  1.27889061e+01  1.03731175e+01\n",
      "   1.84731216e+00  4.77582868e-02]\n",
      " [ 3.06761134e+00  3.85968746e-02  9.44690069e+00  8.92522327e+00\n",
      "   1.32709623e+00  2.60426859e-02]\n",
      " [ 3.22104362e+00  3.41212813e-02  1.13097939e+01  1.16539059e+01\n",
      "   9.58430323e-01  1.81533827e-02]\n",
      " [ 4.88133626e+00  3.06008052e-02  9.21438219e+00  1.02648964e+01\n",
      "   1.28996416e+00  7.00727883e-02]\n",
      " [ 3.86143142e+00  3.60797386e-02  6.04629244e+00  7.08365945e+00\n",
      "   9.93190743e-01  9.16596558e-02]\n",
      " [ 5.39104022e+00  2.23846900e-02  9.04415519e+00  9.03444033e+00\n",
      "   5.99574681e-01  7.35184938e-02]\n",
      " [ 2.72361061e+00  1.90316780e-02  1.08388511e+01  1.06237504e+01\n",
      "   1.27225115e+00  3.45556712e-03]\n",
      " [ 7.13311088e+00  3.35475164e-02  1.04611641e+01  1.00494517e+01\n",
      "   1.41885713e+00  1.54493199e-01]\n",
      " [ 7.30139548e+00  3.97775225e-02  1.14143324e+01  1.13618177e+01\n",
      "   6.39401665e-02  1.51949023e-01]\n",
      " [ 6.23958087e+00  3.46079485e-02  7.19431601e+00  6.97031805e+00\n",
      "   7.13884641e-01  1.49080008e-01]\n",
      " [ 5.59906252e+00  3.55173186e-02  9.25005460e+00  9.15691798e+00\n",
      "   5.89699924e-01  9.75107326e-02]\n",
      " [ 4.75494146e+00  3.55400261e-02  5.96700844e+00  6.68366198e+00\n",
      "   7.85666209e-01  1.20706272e-01]\n",
      " [ 4.80997043e+00  3.17589170e-02  1.39987896e+01  1.28140013e+01\n",
      "   8.89602152e-01  3.82605643e-02]\n",
      " [ 5.21550001e+00  2.77578670e-02  8.99362753e+00  9.73301809e+00\n",
      "   1.68697379e+00  9.04365041e-02]\n",
      " [ 4.00873497e+00  3.21776954e-02  8.75048384e+00  8.06845568e+00\n",
      "   1.04866301e+00  5.53435086e-02]\n",
      " [ 4.11890438e+00  3.17062721e-02  1.00888447e+01  8.84822359e+00\n",
      "   9.53447895e-01  5.40851083e-02]\n",
      " [ 6.04310720e+00  3.00020507e-02  8.43335638e+00  8.19754320e+00\n",
      "   9.53932523e-01  1.25804080e-01]\n",
      " [ 6.93202739e+00  2.48231570e-02  9.12298491e+00  9.16996403e+00\n",
      "   1.78840366e-01  1.09151519e-01]\n",
      " [ 5.28813531e+00  4.49041858e-02  1.11335307e+01  1.06375569e+01\n",
      "   7.08471660e-01  1.10554065e-01]\n",
      " [ 3.50037995e+00  3.68489407e-02  7.29469690e+00  8.06793562e+00\n",
      "   8.88030543e-01  6.65132396e-02]\n",
      " [ 3.13600615e+00  2.45599352e-02  1.13620979e+01  1.04210267e+01\n",
      "   7.56527105e-01  1.00048685e-02]\n",
      " [ 4.68995715e+00  3.41813431e-02  1.10840688e+01  1.12928764e+01\n",
      "   8.45313288e-01  6.20379176e-02]\n",
      " [ 7.08207113e+00  2.31861588e-02  1.18729633e+01  1.12477750e+01\n",
      "   5.43769362e-01  8.77546338e-02]\n",
      " [ 2.35607739e+00  3.14477354e-02  1.06883674e+01  1.07081924e+01\n",
      "   4.41790200e-01 -2.07450703e-03]\n",
      " [ 7.34614265e+00  4.26470682e-02  7.83169784e+00  9.64010086e+00\n",
      "   9.92935319e-01  2.07797635e-01]\n",
      " [ 5.95017600e+00  4.12188598e-02  1.11456644e+01  1.07903929e+01\n",
      "   5.67082858e-01  1.06225252e-01]\n",
      " [ 8.98924915e+00  2.62379830e-02  1.21517610e+01  1.32675005e+01\n",
      "   1.72420468e+00  1.33581653e-01]\n",
      " [ 4.24199854e+00  4.20784039e-02  1.38660962e+01  1.33165440e+01\n",
      "   7.35158878e-01  3.97535617e-02]\n",
      " [ 6.16988048e+00  3.61890677e-02  1.06385294e+01  1.06264809e+01\n",
      "   1.55688650e+00  1.21901081e-01]\n",
      " [ 4.77254077e+00  3.92091972e-02  9.97536310e+00  9.39130451e+00\n",
      "   2.04578158e+00  8.54159202e-02]\n",
      " [ 3.83042493e+00  2.86798061e-02  9.57256199e+00  1.11498078e+01\n",
      "   1.30671740e+00  5.03895512e-02]\n",
      " [ 4.13766519e+00  3.51830733e-02  9.09436275e+00  1.07664731e+01\n",
      "   1.78362199e+00  6.10009614e-02]\n",
      " [ 7.62677220e+00  2.80855668e-02  9.02054539e+00  1.06584139e+01\n",
      "   8.92910691e-01  1.30917794e-01]\n",
      " [ 7.38760266e+00  4.03357138e-02  1.27909931e+01  1.19884998e+01\n",
      "   6.32279163e-01  1.71922724e-01]\n",
      " [ 6.70680106e+00  3.28791232e-02  8.68597270e+00  8.69787635e+00\n",
      "   5.76467213e-01  1.40765677e-01]\n",
      " [ 2.78246440e+00  2.77054770e-02  1.29528504e+01  1.04101345e+01\n",
      "   1.62525710e+00 -3.99364489e-03]\n",
      " [ 8.91175197e+00  3.73510492e-02  5.84524029e+00  6.03910444e+00\n",
      "   5.31481216e-01  2.98517987e-01]\n",
      " [ 8.44214483e+00  3.30576181e-02  1.14671450e+01  1.12630755e+01\n",
      "   7.75491309e-01  1.84630748e-01]\n",
      " [ 4.95193193e+00  3.24204394e-02  1.37881611e+01  1.37689398e+01\n",
      "   6.42999547e-01  4.60616947e-02]\n",
      " [ 6.38672834e+00  4.16055667e-02  1.29277390e+01  1.25441795e+01\n",
      "   1.90409215e+00  1.44924896e-01]\n",
      " [ 6.07136535e+00  2.77791428e-02  9.56203285e+00  9.54367922e+00\n",
      "   1.50771449e-01  1.02682379e-01]\n",
      " [ 6.06627910e+00  3.18140152e-02  9.03650464e+00  7.97708762e+00\n",
      "   1.56411400e+00  8.86993651e-02]\n",
      " [ 8.40551974e+00  3.71469458e-02  1.19171334e+01  1.26274407e+01\n",
      "   3.30685545e-01  1.84656478e-01]\n",
      " [ 8.51942940e+00  4.12215669e-02  8.90083762e+00  1.06432737e+01\n",
      "   1.25118463e+00  2.33752441e-01]\n",
      " [ 4.97782161e+00  2.40474862e-02  1.33517962e+01  1.32056555e+01\n",
      "   1.79772177e+00  3.51133647e-02]\n",
      " [ 2.68722591e+00  2.07012548e-02  1.29973746e+01  9.20524913e+00\n",
      "   1.82540900e+00 -4.03285705e-03]\n",
      " [ 3.53024944e+00  3.34796516e-02  1.09137669e+01  1.04517034e+01\n",
      "   9.28772418e-01  2.86110714e-02]\n",
      " [ 5.68861037e+00  3.66661105e-02  6.87988227e+00  7.22640768e+00\n",
      "   9.42170310e-01  1.50646576e-01]\n",
      " [ 4.30904477e+00  3.25817762e-02  1.00013789e+01  9.92363194e+00\n",
      "   4.78405287e-02  5.05450166e-02]\n",
      " [ 4.28788775e+00  2.90621094e-02  1.31647409e+01  1.39294208e+01\n",
      "   1.21235144e+00  3.31074924e-02]\n",
      " [ 2.65281299e+00  3.54682298e-02  8.46016589e+00  6.46662921e+00\n",
      "   1.46058528e+00  2.04307840e-02]\n",
      " [ 4.45119570e+00  1.88451774e-02  1.16546714e+01  1.03231192e+01\n",
      "   1.05722300e+00  2.87496073e-02]\n",
      " [ 6.00666725e+00  1.98823168e-02  4.23446280e+00  8.14895937e+00\n",
      "   1.20593414e+00  8.66325180e-02]\n",
      " [ 3.13154288e+00  2.43706728e-02  7.65504814e+00  1.02254288e+01\n",
      "   1.25813452e+00  2.81016104e-02]\n",
      " [ 4.75637441e+00  3.14480507e-02  1.07943456e+01  1.27527100e+01\n",
      "   1.82602013e+00  6.32249434e-02]\n",
      " [ 1.47740099e+00  3.21023420e-02  5.71931151e+00  5.55384089e+00\n",
      "   3.75158028e-01  4.02448258e-03]\n",
      " [ 2.69914121e+00  3.07371404e-02  8.80204577e+00  8.66443667e+00\n",
      "   5.85615039e-01  2.02956816e-02]\n",
      " [ 6.42701234e+00  1.79920077e-02  1.18806154e+01  9.05636454e+00\n",
      "   1.66848836e+00  6.11682454e-02]\n",
      " [ 5.12695467e+00  3.56657037e-02  8.45776275e+00  9.50713006e+00\n",
      "   1.21127490e+00  1.06044991e-01]\n",
      " [ 8.54961049e+00  3.63409136e-02  1.16016793e+01  1.13381898e+01\n",
      "   3.19415363e-01  1.82473903e-01]\n",
      " [ 5.37290606e+00  3.45383058e-02  9.02903659e+00  8.37334929e+00\n",
      "   6.17553412e-01  1.03735034e-01]\n",
      " [ 4.22237855e+00  1.94636470e-02  9.99596875e+00  1.12312761e+01\n",
      "   1.72550292e+00  3.76654793e-02]\n",
      " [ 7.45769713e+00  3.38333608e-02  1.34475562e+01  1.32784392e+01\n",
      "   9.16269685e-01  1.14104057e-01]\n",
      " [ 7.48510231e-01  2.53612296e-02  1.21295192e+01  1.13571186e+01\n",
      "   9.85040622e-01 -1.83173649e-02]\n",
      " [ 5.01495821e+00  2.73870667e-02  1.36617905e+01  1.25432600e+01\n",
      "   1.18020480e+00  4.50988440e-02]\n",
      " [ 3.90815614e+00  2.82868462e-02  1.09014858e+01  1.13961909e+01\n",
      "   3.55972942e-01  3.39538227e-02]\n",
      " [ 5.43181249e+00  3.73656672e-02  6.02200801e+00  9.18872997e+00\n",
      "   2.21842056e+00  1.37045710e-01]\n",
      " [ 4.68593086e+00  2.79146559e-02  1.17217807e+01  1.14343530e+01\n",
      "   4.91910084e-01  5.44218576e-02]\n",
      " [ 5.31413972e+00  3.64241089e-02  7.82866056e+00  9.19607278e+00\n",
      "   1.32745605e+00  1.01150853e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad086a5",
   "metadata": {},
   "source": [
    "Okay define the priors as uniform distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 3\n",
    "\n",
    "# there are three priors for the non-hierarchical run of SBI:\n",
    "low_bounds = torch.tensor([1, np.pi/500, 1])\n",
    "high_bounds = torch.tensor([10, 3*np.pi/200, 20])\n",
    "# length, theta, μ_a_g, σ_a_g, σ = thetas\n",
    "\n",
    "prior = utils.BoxUniform(low = low_bounds, high = high_bounds)\n",
    "print(prior.sample())\n",
    "\n",
    "# there are \n",
    "low_bounds = torch.tensor([1, np.pi/500, 1, 0.1])\n",
    "high_bounds = torch.tensor([10, 3*np.pi/200, 20, 5])\n",
    "# length, theta, μ_a_g, σ_a_g, σ = thetas\n",
    "\n",
    "prior_hierarchical = utils.BoxUniform(low = low_bounds, high = high_bounds)\n",
    "print(prior.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(thetas):#, percent_errors):\n",
    "    # just plop the pendulum within here\n",
    "    length, theta, a_g = thetas\n",
    "    #print('heres what were inputting', thetas, a_g)\n",
    "    #length_percent_error_all, theta_percent_error_all, a_g_percent_error_all = \\\n",
    "    #    percent_errors\n",
    "    pendulum = Pendulum(\n",
    "        pendulum_arm_length=float(length),\n",
    "        starting_angle_radians=float(theta),\n",
    "        acceleration_due_to_gravity=float(a_g),\n",
    "        noise_std_percent={\n",
    "            \"pendulum_arm_length\": 0.0,\n",
    "            \"starting_angle_radians\": 0.1,\n",
    "            \"acceleration_due_to_gravity\": 0.0,\n",
    "        },\n",
    "    )\n",
    "    output = np.array(pendulum.create_object(np.linspace(0,2,100), noiseless=False))\n",
    "    #torch.tensor(pendulum.create_object(0.75, noiseless=False))\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def linear_gaussian(theta):\n",
    "    output = theta + 1.0 + torch.randn_like(theta) * 0.1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041cd17-d2fe-434e-948f-2e4ebdaf6c05",
   "metadata": {},
   "source": [
    "## Hierarchical SBI\n",
    "Okay so normally the simulator functions within SBI to return one observation for every time you sample from the prior. So how do we build this within a hierarchical structure? Also how do we preserve the groupings?\n",
    "1. Do we need to simulate a set of observations (ie multiple observations)\n",
    "2. Do we need a trickle down effect where you draw from population level parameter and then this determines which group you fall into, so it's still one observation all the way through?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a669c910-4176-481e-bdcc-f7104c7da814",
   "metadata": {},
   "source": [
    "A simulator simply takes parameters (thetas) and outputs data (x). So in the hierarchical pendulum example, we would be giving it length, theta, μ_a_g, and σ_a_g. It would take these and have a deterministic way to get to a_g, maybe from randomly drawing from the μ_a_g and σ_a_g distribution?\n",
    "\n",
    "In the first case, we would draw two a_g values randomly and then for each of these we would have four pendulums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae279a8-44f7-4aaa-8e5f-e14a592a625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it actually possible to set up a hierarchical model in this way?\n",
    "# can we actually that the pendulums are actually on two different planets?\n",
    "# how do you set up a simulator so that it knows about placing pendulums into groups?\n",
    "\n",
    "import jax\n",
    "\n",
    "\n",
    "# okay so you need to pass it parameters on all levels\n",
    "# each of these parameters will have a prior\n",
    "def hierarchical_simulator_set(thetas):\n",
    "    # except length will have 8 elements as will theta\n",
    "    length0, length1, length2, length3, theta0, theta1, theta2, theta3, μ_a_g, σ_a_g = thetas\n",
    "\n",
    "    length = [length0, length1, length2, length3]\n",
    "    theta = [theta0, theta1, theta2, theta3]\n",
    "    # draw two a_g values\n",
    "    rng_key = jax.random.PRNGKey(0)  # You can use any valid random key\n",
    "    #a_g = np.zeros(2)\n",
    "    #print(μ_a_g, σ_a_g)\n",
    "    #print(float(μ_a_g), float(σ_a_g))\n",
    "    a_g_0 = numpyro.sample(\"a_g\", numpyro.distributions.TruncatedNormal(float(μ_a_g), float(σ_a_g), low = 0.01), rng_key = rng_key)\n",
    "    rng_key = jax.random.PRNGKey(1)  # You can use any valid random key\n",
    "    a_g_1 = numpyro.sample(\"a_g\", numpyro.distributions.TruncatedNormal(float(μ_a_g), float(σ_a_g), low = 0.01), rng_key = rng_key)\n",
    "\n",
    "    a_g = [a_g_0, a_g_1]\n",
    "    #print('a_g', a_g)\n",
    "    \n",
    "    output = []#np.zeros((2,4))\n",
    "    for j in range(2):\n",
    "        for i in range(4):\n",
    "            #print('input params are', float(length[i]), float(theta[i]), float(a_g[j]))\n",
    "            pendulum = Pendulum(\n",
    "                pendulum_arm_length=float(length[i]),\n",
    "                starting_angle_radians=float(theta[i]),\n",
    "                acceleration_due_to_gravity=float(a_g[j]),\n",
    "                noise_std_percent={\n",
    "                    \"pendulum_arm_length\": 0.0,\n",
    "                    \"starting_angle_radians\": 0.1,\n",
    "                    \"acceleration_due_to_gravity\": 0.0,\n",
    "                },\n",
    "            )\n",
    "            #np.linspace(0,2,100)\n",
    "            #print('output', np.array(pendulum.create_object(0.75, noiseless=False)))\n",
    "            output.append(pendulum.create_object(0.75, noiseless=False))\n",
    "    #torch.tensor(pendulum.create_object(0.75, noiseless=False))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def hierarchical_simulator_trickle_down(thetas):\n",
    "    # just plop the pendulum within here\n",
    "\n",
    "    #μ_a_g\n",
    "    #σ_a_g\n",
    "    #a_g = numpyro.sample(\"a_g\", dist.TruncatedNormal(μ_a_g, σ_a_g, low = 0.01))\n",
    "    # ^ I'm not sure how to to draw one parameter nested from another\n",
    "    # in SBI you don't make a sampling distribution, you set an exact equality\n",
    "    # unless you're introducing noise\n",
    "    # and then there's some element of random sampling\n",
    "\n",
    "    length, theta, μ_a_g, σ_a_g = thetas #, σ\n",
    "    \n",
    "    '''\n",
    "    μ_a_g = numpyro.sample(\"μ_a_g\", dist.TruncatedNormal(12.5, 2, low = 0.01))\n",
    "    # scale parameters should be log uniform so that they don't go negative \n",
    "    # and so that they're not uniform\n",
    "    # 1 / x in linear space\n",
    "    σ_a_g = numpyro.sample(\"σ_a_g\", dist.TruncatedNormal(2, 0.5, low = 0.01))\n",
    "    '''\n",
    "    n_planets = 2\n",
    "    n_pendulums = 8\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(0)  # You can use any valid random key\n",
    "\n",
    "    ## plates are a numpyro primitive or context manager for handing conditionally independence\n",
    "    ## for instance, we wish to model a_g for each planet independently\n",
    "    with numpyro.plate(\"planet_i\", n_planets):\n",
    "        #a_g = numpyro.sample(\"a_g\", numpyro.distributions.TruncatedNormal(μ_a_g, σ_a_g, low = 0.01))\n",
    "        a_g = numpyro.sample(\"a_g\", numpyro.distributions.TruncatedNormal(μ_a_g, σ_a_g, low = 0.01), rng_key = rng_key)\n",
    "        \n",
    "        \n",
    "        print(a_g)\n",
    "        #a_g = numpyro.sample(\"a_g\", utils.MultivariateNormal(μ_a_g, σ_a_g))\n",
    "        #a_g = numpyro.sample(\"a_g\", torch.normal(μ_a_g, σ_a_g))\n",
    "        \n",
    "    '''\n",
    "    ## we also wish to model L and theta for each pendulum independently\n",
    "    ## here we draw from an uniform distribution\n",
    "    with numpyro.plate(\"pend_i\", n_pendulums):\n",
    "        L = 5#numpyro.sample(\"L\", dist.TruncatedNormal(5, 2, low = 0.01))\n",
    "        theta = numpyro.sample(\"theta\", dist.TruncatedNormal(jnp.pi/100,jnp.pi/500, low = 0.00001))\n",
    "    '''\n",
    "    ## σ is the error on the position measurement for each moment in time\n",
    "    ## we also model this\n",
    "    ## eventually, we should also model the error on each parameter independently?\n",
    "    ## draw from an exponential distribution parameterized by a rate parameter\n",
    "    ## the mean of an exponential distribution is 1/r where r is the rate parameter\n",
    "    ## exponential distributions are never negative. This is good for error.\n",
    "    #σ = numpyro.sample(\"σ\", dist.Exponential(exponential))#dist.Uniform(0, 0.1))#dist.HalfNormal(2.0))\n",
    "    \n",
    "    ## the moments in time are not independent, so we do not place the following in a plate\n",
    "    ## instead, the brackets segment the model by pendulum and by planet,\n",
    "    ## telling us how to conduct the inference\n",
    "    #modelx = L * jnp.sin(theta[pendulum_code] * jnp.cos(jnp.sqrt(a_g[planet_code] / L) * times))\n",
    "    \n",
    "    \n",
    "    #print('heres what were inputting', thetas, a_g)\n",
    "    #length_percent_error_all, theta_percent_error_all, a_g_percent_error_all = \\\n",
    "    #    percent_errors\n",
    "    pendulum = Pendulum(\n",
    "        pendulum_arm_length=float(length),\n",
    "        starting_angle_radians=float(theta),\n",
    "        acceleration_due_to_gravity=float(a_g),\n",
    "        noise_std_percent={\n",
    "            \"pendulum_arm_length\": 0.0,\n",
    "            \"starting_angle_radians\": 0.1,\n",
    "            \"acceleration_due_to_gravity\": 0.0,\n",
    "        },\n",
    "    )\n",
    "    output = np.array(pendulum.create_object(np.linspace(0,2,100), noiseless=False))\n",
    "    #torch.tensor(pendulum.create_object(0.75, noiseless=False))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0effa",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = infer(simulator, prior, \"SNPE\", num_simulations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_o_1 = simulator([5, np.pi/100, 5])\n",
    "x_o_1 = simulator([5, np.pi/200, 7])\n",
    "print(x_o_1)\n",
    "posterior_samples_1 = posterior.sample((10000,), x=x_o_1)\n",
    "\n",
    "# plot posterior samples\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_1, \n",
    "    labels = ['L',r'$\\theta_0$','$a_g$'],\n",
    "    limits = [[0,10],[np.pi/200,3*np.pi/200],[0,10]],\n",
    "    truths = [5, np.pi/100, 5],\n",
    "    figsize=(5, 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ae52a-3b50-4484-8ffc-aa373ab1c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hierarchical_simulator_set\n",
    "low_bounds = torch.tensor([1,1,1,1,\n",
    "                           np.pi/500,np.pi/500,np.pi/500,np.pi/500,\n",
    "                           1, 0.1])\n",
    "high_bounds = torch.tensor([10,10,10,10,\n",
    "                           3*np.pi/200,3*np.pi/200,3*np.pi/200,3*np.pi/200,\n",
    "                           20, 5])\n",
    "# length, theta, μ_a_g, σ_a_g, σ = thetas\n",
    "\n",
    "prior_hierarchical_set = utils.BoxUniform(low = low_bounds, high = high_bounds)\n",
    "print(prior_hierarchical_set.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f41380-cd43-4063-b3e7-64c65f40b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the simulator\n",
    "params = prior_hierarchical_set.sample()\n",
    "print('params', params, 'x', hierarchical_simulator_set(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5a16a-f9d3-4a39-9fea-d1f549a8a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = infer(hierarchical_simulator_set, prior_hierarchical_set, \"SNPE\", num_simulations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141fc7f-f4c2-449c-856a-ca6b69db5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = prior_hierarchical_set.sample()\n",
    "print('true params', params)\n",
    "x_o_1 = hierarchical_simulator_set(params)\n",
    "print('observed xs', x_o_1)\n",
    "# give it all the same position\n",
    "xs = [0.018, 0.018, 0.018, 0.018, 0.018, 0.018, 0.018, 0.018]\n",
    "posterior_samples_1 = posterior.sample((10000,), x=xs)#x_o_1)\n",
    "\n",
    "# plot posterior samples\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples_1, \n",
    "    #labels = ['L',r'$\\theta_0$','$a_g$'],\n",
    "    #limits = [[0,10],[np.pi/200,3*np.pi/200],[0,10]],\n",
    "    truths = params,\n",
    "    figsize=(15, 15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27794cb-870c-43cc-91b6-ae7dac8b109b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe48343-3b8b-4d63-a870-d3842b5fd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
