{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b47e868-ace6-4987-8878-c4f346ff3dad",
   "metadata": {},
   "source": [
    "## Make the mountain plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "855fbca4-4074-456e-ad71-0397003136f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze.analyze import AggregateCheckpoints\n",
    "from models.models import model_setup_DER, model_setup_DE\n",
    "from data.data import DataPreparation\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326ba0a2-e566-4e01-8a58-c9707708421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_title_lookup = {'predictive': 'output injection', 'feature': 'input injection'}\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoints = AggregateCheckpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908d84e8-c1fc-4cdb-a94b-f5a9535432a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sims 10000\n",
      "NO WERE NOT VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: predictive.\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5m/wnsjjcln435g2yq5mmxf45k00000gz/T/ipykernel_23666/798972974.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  df = {key: torch.tensor(value) if not isinstance(value, TensorDataset) else value for key, value in df_array.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "number of sims 10000\n",
      "YES WERE VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: feature.\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "using this model 10\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "number of sims 10000\n",
      "NO WERE NOT VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: predictive.\n",
      "number of sims 10000\n",
      "YES WERE VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: feature.\n",
      "number of sims 10000\n",
      "NO WERE NOT VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: predictive.\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "number of sims 10000\n",
      "YES WERE VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: feature.\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "using this model 0\n",
      "using this model 1\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  2\n",
      "using this model 3\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  4\n",
      "using this model 5\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  6\n",
      "using this model 7\n",
      "using this model 8\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  9\n",
      "using this model 10\n",
      "using this model 11\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  12\n",
      "using this model 13\n",
      "using this model 14\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "number of sims 10000\n",
      "NO WERE NOT VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: predictive.\n",
      "number of sims 10000\n",
      "YES WERE VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: feature.\n",
      "number of sims 10000\n",
      "NO WERE NOT VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: predictive.\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "number of sims 10000\n",
      "YES WERE VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: feature.\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "using this model 5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "using this model 0\n",
      "using this model 1\n",
      "using this model 2\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  3\n",
      "using this model 4\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  5\n",
      "using this model 6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "using this model 10\n",
      "using this model 11\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  0\n",
      "using this model 1\n",
      "using this model 2\n",
      "using this model 3\n",
      "using this model 4\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  5\n",
      "All values in y_pred[:,1] are the same or they are really high\n",
      "not using this model  6\n",
      "using this model 7\n",
      "using this model 8\n",
      "using this model 9\n",
      "using this model 10\n",
      "using this model 11\n",
      "using this model 12\n",
      "number of sims 10000\n",
      "NO WERE NOT VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: predictive.\n",
      "number of sims 10000\n",
      "YES WERE VARYING SIGMA\n",
      "linear_homoskedastic simulation data generated,                 with noise injected type: feature.\n"
     ]
    }
   ],
   "source": [
    "uniform = True\n",
    "prescription = \"linear_homoskedastic\"\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "\n",
    "'''\n",
    "inject_type_list = [\"predictive\"]\n",
    "data_dim_list = [\"2D\"]\n",
    "model_type = [\"DE\"]\n",
    "noise_list = [\"low\"]\n",
    "'''\n",
    "\n",
    "\n",
    "# these are the three colors for the three noise levels\n",
    "color_list = [\"#DFA316\", \"#339989\", \"#ED6A5A\", \"#292F36\"]\n",
    "size_df_linear = 10000 # 1000\n",
    "size_df_image = 175000\n",
    "epoch = 99\n",
    "ensemble = True\n",
    "n_models = 15\n",
    "\n",
    "mega_dict = {}\n",
    "\n",
    "# Nested loops to fill the dictionary\n",
    "for noise in noise_list:\n",
    "    mega_dict[noise] = {}  # Create a sub-dictionary for each noise level\n",
    "    for model in model_type:\n",
    "        mega_dict[noise][model] = {}  # Create a sub-dictionary for each model type\n",
    "        for dim in data_dim_list:\n",
    "            mega_dict[noise][model][dim] = {}  # Create a sub-dictionary for each data dimension\n",
    "            for inject_type in inject_type_list:\n",
    "                mega_dict[noise][model][dim][inject_type] = []\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "for n, noise in enumerate(noise_list):\n",
    "    for m, model in enumerate(model_type):\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "\n",
    "                chk = 0\n",
    "                \n",
    "                # make the test set\n",
    "                data = DataPreparation()\n",
    "                \n",
    "                if dim == \"0D\":\n",
    "                    data.sample_params_from_prior(size_df_linear)\n",
    "                    if inject_type == \"feature\":\n",
    "                        data.simulate_data(\n",
    "                            data.params,\n",
    "                            noise,\n",
    "                            \"linear_homoskedastic\",\n",
    "                            inject_type=inject_type,\n",
    "                            seed=41,\n",
    "                            vary_sigma=True,\n",
    "                        )\n",
    "                    else:\n",
    "                        sigma = DataPreparation.get_sigma(\n",
    "                            noise, inject_type=inject_type, data_dimension=dim)\n",
    "                        data.simulate_data(\n",
    "                            data.params,\n",
    "                            sigma,\n",
    "                            \"linear_homoskedastic\",\n",
    "                            inject_type=inject_type,\n",
    "                            seed=41,\n",
    "                        )\n",
    "                    df_array = data.get_dict()\n",
    "                    df = {key: torch.tensor(value) if not isinstance(value, TensorDataset) else value for key, value in df_array.items()}\n",
    "                    len_df = len(df[\"params\"][:, 0].numpy())\n",
    "                    len_x = np.shape(df[\"output\"])[1]\n",
    "                    ms_array = np.repeat(df[\"params\"][:, 0].numpy(), len_x)\n",
    "                    bs_array = np.repeat(df[\"params\"][:, 1].numpy(), len_x)\n",
    "                    xs_array = np.reshape(df[\"inputs\"].numpy(), (len_df * len_x))\n",
    "                    ys_array = np.reshape(df[\"output\"].numpy(), (len_df * len_x))\n",
    "                    inputs = np.array([xs_array, ms_array, bs_array]).T\n",
    "                    model_inputs = inputs\n",
    "                    model_outputs = ys_array\n",
    "                elif dim == \"2D\":\n",
    "                    sigma = DataPreparation.get_sigma(\n",
    "                        noise, inject_type=inject_type, data_dimension=dim)\n",
    "                    data.sample_params_from_prior(\n",
    "                        size_df_image,\n",
    "                        low=[0, 1, -1.5],\n",
    "                        high=[0.01, 10, 1.5],\n",
    "                        n_params=3,\n",
    "                        seed=41)\n",
    "                    model_inputs, model_outputs = data.simulate_data_2d(\n",
    "                        size_df_image,\n",
    "                        data.params,\n",
    "                        image_size=32,\n",
    "                        inject_type=inject_type,\n",
    "                        sigma=sigma)\n",
    "                if uniform:\n",
    "                    model_inputs, model_outputs = DataPreparation.select_uniform(\n",
    "                        model_inputs, model_outputs, dim, verbose=False, rs=40\n",
    "                    )\n",
    "                x_test = model_inputs\n",
    "                y_test = model_outputs\n",
    "                \n",
    "                path = \"../DeepUQResources/checkpoints/\"\n",
    "                if model == \"DER\":\n",
    "                    setupmodel, lossFn = model_setup_DER(\n",
    "                        model, DEVICE, n_hidden=64, data_type=dim)\n",
    "                    COEFF = 0.01\n",
    "                    file_name = (\n",
    "                        str(path)\n",
    "                        + f\"{model}_{prescription}_{inject_type}_{dim}\"\n",
    "                        + f\"_noise_{noise}_loss_DER_COEFF_{COEFF}_epoch_{epoch}\"\n",
    "                    )\n",
    "                    if dim == \"0D\":\n",
    "                        file_name += f\"_sizedf_{size_df_linear}\"\n",
    "                    elif dim == \"2D\":\n",
    "                        file_name += f\"_sizedf_{size_df_image}\"\n",
    "                    file_name += \".pt\"\n",
    "                    try:\n",
    "                        #print('loading this file', file_name)\n",
    "                        chk = torch.load(file_name, map_location=DEVICE)\n",
    "                    except FileNotFoundError:\n",
    "                        #print(\"cannot find this model\", file_name)\n",
    "                        continue\n",
    "                    setupmodel.load_state_dict(chk.get(\"model_state_dict\"))\n",
    "                    setupmodel.eval()\n",
    "\n",
    "                    y_pred = setupmodel(torch.Tensor(x_test)).detach().numpy()\n",
    "                    beta = y_pred[:, 3]\n",
    "                    nu = y_pred[:, 1]\n",
    "                    alpha = y_pred[:, 2]\n",
    "                    u_al = np.sqrt(abs(beta * (1 + nu) / (alpha * nu)))\n",
    "                    \n",
    "                    \n",
    "                elif model == \"DE\":\n",
    "                    models_used = 0\n",
    "                    loss = \"bnll_loss\"\n",
    "                    setupmodel, lossFn = model_setup_DE(\n",
    "                        loss, DEVICE, n_hidden=64, data_type=dim)\n",
    "                    BETA = 0.5\n",
    "                    u_al = []\n",
    "                    for m in range(n_models):\n",
    "                        if models_used > 9:\n",
    "                            break\n",
    "                        file_name = (\n",
    "                            str(path) +\n",
    "                            f\"{model}_{prescription}_{inject_type}_{dim}\"\n",
    "                            f\"_noise_{noise}_beta_{BETA}_nmodel_{m}_epoch_{epoch}\"\n",
    "                        )\n",
    "                        if dim == \"0D\":\n",
    "                            file_name += f\"_sizedf_{size_df_linear}\"\n",
    "                        elif dim == \"2D\":\n",
    "                            file_name += f\"_sizedf_{size_df_image}\"\n",
    "                        file_name += \".pt\"\n",
    "                        try:\n",
    "                            #print('loading this file', file_name)\n",
    "                            chk = torch.load(file_name, map_location=DEVICE)\n",
    "                        except FileNotFoundError:\n",
    "                            # print(\"cannot find this model\", file_name)\n",
    "                            continue\n",
    "                        setupmodel.load_state_dict(chk.get(\"model_state_dict\"))\n",
    "                        setupmodel.eval()\n",
    "                        y_pred = setupmodel(torch.Tensor(x_test)).detach().numpy()\n",
    "                        # for some reason if the model fails it predicts\n",
    "                        # really large values for sigma\n",
    "                        \n",
    "                        if np.all(y_pred[:, 1] == y_pred[0, 1]) or np.mean(np.sqrt(y_pred[:, 1])) > 0.2:\n",
    "                            # All values are the same\n",
    "                            print(\"All values in y_pred[:,1] are the same or they are really high\")\n",
    "                            # then we need to skip this model\n",
    "                            print('not using this model ', m)\n",
    "                            continue\n",
    "                        else:\n",
    "                            '''\n",
    "                            plt.clf()\n",
    "                            plt.hist(np.sqrt(y_pred[:, 1]), bins=100)\n",
    "                            plt.title(f'model m {m}')\n",
    "                            plt.show()\n",
    "                            '''\n",
    "                            print('using this model', m)\n",
    "                            models_used += 1\n",
    "                            #print('using this model ', m)            \n",
    "                        u_al_one = np.sqrt(y_pred[:, 1])\n",
    "                        u_al.append(u_al_one)\n",
    "\n",
    "                        \n",
    "                # populate the mega dict\n",
    "                mega_dict[noise][model][dim][inject_type] = u_al\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "030afb67-90de-430b-98ff-345124ff631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mega dict {'low': {'DE': {'0D': {'predictive': [array([0.01110306, 0.01086861, 0.01085957, ..., 0.0119775 , 0.01462499,\n",
      "       0.01565562], dtype=float32), array([0.01036897, 0.01048306, 0.01040894, ..., 0.01133265, 0.01535858,\n",
      "       0.01697909], dtype=float32), array([0.01039905, 0.01160455, 0.01062732, ..., 0.01184992, 0.0144916 ,\n",
      "       0.01495334], dtype=float32), array([0.01092363, 0.01144333, 0.01101677, ..., 0.01218419, 0.01519122,\n",
      "       0.01506914], dtype=float32), array([0.01040624, 0.01062425, 0.01041533, ..., 0.01101052, 0.01184662,\n",
      "       0.01275155], dtype=float32), array([0.0096012 , 0.01113802, 0.00951285, ..., 0.01115705, 0.01403877,\n",
      "       0.01494971], dtype=float32), array([0.0103732 , 0.01055982, 0.01024856, ..., 0.01095134, 0.01178694,\n",
      "       0.01224134], dtype=float32), array([0.01094032, 0.01119366, 0.01084939, ..., 0.01056638, 0.01280092,\n",
      "       0.01439112], dtype=float32), array([0.0107816 , 0.01083841, 0.01085345, ..., 0.01131167, 0.01243775,\n",
      "       0.01364379], dtype=float32), array([0.01183409, 0.01191474, 0.01173976, ..., 0.01184551, 0.01638852,\n",
      "       0.01647449], dtype=float32)], 'feature': [array([0.01039666, 0.01039319, 0.00987083, ..., 0.01153724, 0.01359452,\n",
      "       0.01081189], dtype=float32), array([0.01079839, 0.01075679, 0.01076835, ..., 0.0118775 , 0.01412811,\n",
      "       0.01203848], dtype=float32), array([0.01124502, 0.01148062, 0.01078215, ..., 0.01349362, 0.01632767,\n",
      "       0.01340629], dtype=float32), array([0.01027501, 0.00987013, 0.00883277, ..., 0.01034935, 0.01264486,\n",
      "       0.01034434], dtype=float32), array([0.00995758, 0.01011509, 0.00959605, ..., 0.01148498, 0.014001  ,\n",
      "       0.00988882], dtype=float32), array([0.01133578, 0.0110078 , 0.01060239, ..., 0.01202881, 0.01482852,\n",
      "       0.01154657], dtype=float32), array([0.01269015, 0.01274049, 0.01215896, ..., 0.01382045, 0.01715939,\n",
      "       0.01316494], dtype=float32), array([0.01002258, 0.01000057, 0.00996318, ..., 0.01095327, 0.01377266,\n",
      "       0.01045565], dtype=float32), array([0.01046818, 0.01022074, 0.01037063, ..., 0.01098558, 0.01257024,\n",
      "       0.01083986], dtype=float32), array([0.01008307, 0.01001326, 0.0090246 , ..., 0.01213401, 0.01432687,\n",
      "       0.01158541], dtype=float32)]}, '2D': {'predictive': [array([0.01862333, 0.01837318, 0.01885177, ..., 0.02661155, 0.03058746,\n",
      "       0.02854851], dtype=float32), array([0.01344998, 0.01325974, 0.01336691, ..., 0.01433965, 0.01565675,\n",
      "       0.01687989], dtype=float32), array([0.0143821 , 0.01529277, 0.01381037, ..., 0.01814303, 0.02232345,\n",
      "       0.01608186], dtype=float32), array([0.01414538, 0.01453449, 0.01416551, ..., 0.0158563 , 0.0169375 ,\n",
      "       0.02035727], dtype=float32), array([0.01252232, 0.01302006, 0.01236059, ..., 0.01507619, 0.01792325,\n",
      "       0.01586911], dtype=float32), array([0.04302176, 0.04371862, 0.04306824, ..., 0.05332246, 0.06075431,\n",
      "       0.05622256], dtype=float32), array([0.01140792, 0.01163971, 0.01091379, ..., 0.01339334, 0.01522191,\n",
      "       0.01379374], dtype=float32), array([0.0126838 , 0.01308882, 0.01198112, ..., 0.01451982, 0.01569358,\n",
      "       0.01506784], dtype=float32), array([0.01625254, 0.01619476, 0.01586944, ..., 0.0183844 , 0.02049686,\n",
      "       0.01941232], dtype=float32), array([0.01284491, 0.01317424, 0.01284544, ..., 0.01359983, 0.0156854 ,\n",
      "       0.01560761], dtype=float32)], 'feature': [array([0.01018766, 0.01129762, 0.01045432, ..., 0.0188586 , 0.01470943,\n",
      "       0.02155701], dtype=float32), array([0.01092874, 0.01099096, 0.01095629, ..., 0.01678045, 0.0138381 ,\n",
      "       0.01706619], dtype=float32), array([0.01461303, 0.01512774, 0.01476663, ..., 0.01248041, 0.01245806,\n",
      "       0.01205033], dtype=float32), array([0.00798417, 0.00884427, 0.0082256 , ..., 0.01393432, 0.01179153,\n",
      "       0.01456057], dtype=float32), array([0.01750282, 0.01669321, 0.01726272, ..., 0.02578799, 0.02538576,\n",
      "       0.02341061], dtype=float32), array([0.01331214, 0.01312018, 0.01329216, ..., 0.01962049, 0.01690758,\n",
      "       0.02019212], dtype=float32), array([0.01367158, 0.01241224, 0.01330214, ..., 0.01446632, 0.01406331,\n",
      "       0.01484093], dtype=float32), array([0.02032693, 0.02225305, 0.02086084, ..., 0.03524847, 0.03401764,\n",
      "       0.03481729], dtype=float32), array([0.01161778, 0.01139739, 0.01153916, ..., 0.01671261, 0.01559788,\n",
      "       0.01583898], dtype=float32), array([0.01236218, 0.01221171, 0.01231976, ..., 0.01958676, 0.01776428,\n",
      "       0.01890214], dtype=float32)]}}, 'DER': {'0D': {'predictive': array([0.01087422, 0.01043076, 0.01072585, ..., 0.01114199, 0.01587274,\n",
      "       0.01774715], dtype=float32), 'feature': array([0.00919869, 0.00931985, 0.00910251, ..., 0.01082002, 0.01293393,\n",
      "       0.01032551], dtype=float32)}, '2D': {'predictive': array([0.0123488 , 0.01258389, 0.01206355, ..., 0.01702174, 0.02035674,\n",
      "       0.01705857], dtype=float32), 'feature': array([0.00979856, 0.00953045, 0.0097234 , ..., 0.01796039, 0.01728817,\n",
      "       0.01742245], dtype=float32)}}}, 'medium': {'DE': {'0D': {'predictive': [array([0.03362933, 0.04649534, 0.03355299, ..., 0.04348518, 0.04552095,\n",
      "       0.04511426], dtype=float32), array([0.03809358, 0.04747111, 0.03802662, ..., 0.03939162, 0.04683693,\n",
      "       0.04575246], dtype=float32), array([0.03493804, 0.0476257 , 0.03490281, ..., 0.04167011, 0.04392439,\n",
      "       0.04436877], dtype=float32), array([0.03432272, 0.05027607, 0.03427649, ..., 0.03988098, 0.05051689,\n",
      "       0.05014914], dtype=float32), array([0.03639059, 0.05117306, 0.03630465, ..., 0.04293332, 0.04673738,\n",
      "       0.04540165], dtype=float32), array([0.03575423, 0.04969132, 0.03572151, ..., 0.04350152, 0.04626914,\n",
      "       0.04549183], dtype=float32), array([0.0367745 , 0.04999436, 0.03671195, ..., 0.03695001, 0.04555338,\n",
      "       0.04676592], dtype=float32), array([0.03170745, 0.04545435, 0.03163914, ..., 0.04179115, 0.04684936,\n",
      "       0.04415101], dtype=float32), array([0.03586529, 0.04854294, 0.03586892, ..., 0.04579798, 0.05082235,\n",
      "       0.04940903], dtype=float32), array([0.03353226, 0.04806696, 0.03347129, ..., 0.04152262, 0.04536045,\n",
      "       0.0443688 ], dtype=float32)], 'feature': [array([0.0486243 , 0.05095286, 0.04048841, ..., 0.05061709, 0.04588993,\n",
      "       0.05089735], dtype=float32), array([0.04604969, 0.04884536, 0.04057943, ..., 0.05030331, 0.04324025,\n",
      "       0.05077726], dtype=float32), array([0.04387178, 0.04729182, 0.03917541, ..., 0.05085476, 0.04893314,\n",
      "       0.05023696], dtype=float32), array([0.0448947 , 0.0486271 , 0.03977938, ..., 0.04890052, 0.04467835,\n",
      "       0.04768401], dtype=float32), array([0.04859652, 0.05091152, 0.04109582, ..., 0.0524767 , 0.04974036,\n",
      "       0.05061614], dtype=float32), array([0.04633158, 0.04888481, 0.03891785, ..., 0.05139281, 0.04736391,\n",
      "       0.05020103], dtype=float32), array([0.04858014, 0.05057187, 0.04233804, ..., 0.05035365, 0.04732181,\n",
      "       0.04990376], dtype=float32), array([0.04434218, 0.04907839, 0.03867815, ..., 0.04854168, 0.04648422,\n",
      "       0.04775339], dtype=float32), array([0.04764387, 0.04955425, 0.04267038, ..., 0.05241654, 0.05030371,\n",
      "       0.05058169], dtype=float32), array([0.04581095, 0.0472309 , 0.041525  , ..., 0.04934155, 0.04612053,\n",
      "       0.04827731], dtype=float32)]}, '2D': {'predictive': [array([0.05892178, 0.05950018, 0.05819944, ..., 0.06672164, 0.06359014,\n",
      "       0.06805913], dtype=float32), array([0.05267177, 0.05301298, 0.05383293, ..., 0.05147097, 0.0486037 ,\n",
      "       0.05621057], dtype=float32), array([0.0501595 , 0.0513421 , 0.05067803, ..., 0.05492767, 0.05531716,\n",
      "       0.05572781], dtype=float32), array([0.0497175 , 0.04928183, 0.0507947 , ..., 0.05579638, 0.05370637,\n",
      "       0.05782994], dtype=float32), array([0.05547655, 0.05625105, 0.05511147, ..., 0.05945174, 0.05668113,\n",
      "       0.06081819], dtype=float32), array([0.05226276, 0.05289138, 0.05183488, ..., 0.05293396, 0.05032929,\n",
      "       0.05516361], dtype=float32), array([0.05975892, 0.05406318, 0.06120479, ..., 0.06294893, 0.06023952,\n",
      "       0.06506199], dtype=float32), array([0.05562674, 0.05269859, 0.05666823, ..., 0.05832517, 0.05577222,\n",
      "       0.05824497], dtype=float32), array([0.05212077, 0.05362676, 0.05197629, ..., 0.05697261, 0.05453858,\n",
      "       0.05763714], dtype=float32), array([0.0545843 , 0.05090299, 0.05700065, ..., 0.05943202, 0.0577875 ,\n",
      "       0.062871  ], dtype=float32)], 'feature': [array([0.03199365, 0.03315038, 0.03172708, ..., 0.0557248 , 0.05619278,\n",
      "       0.05463593], dtype=float32), array([0.02986882, 0.03135249, 0.02951059, ..., 0.03946636, 0.03607612,\n",
      "       0.04234985], dtype=float32), array([0.0272282 , 0.02830527, 0.02667489, ..., 0.03699932, 0.03200508,\n",
      "       0.0388223 ], dtype=float32), array([0.02828505, 0.02980791, 0.02775342, ..., 0.04464521, 0.0428702 ,\n",
      "       0.04558215], dtype=float32), array([0.02553936, 0.02751197, 0.02511149, ..., 0.04107508, 0.03899172,\n",
      "       0.04309636], dtype=float32), array([0.03246282, 0.03260225, 0.03229341, ..., 0.04570025, 0.04160829,\n",
      "       0.04745555], dtype=float32), array([0.02712385, 0.02826094, 0.02693127, ..., 0.03792608, 0.03407475,\n",
      "       0.04045847], dtype=float32), array([0.02467028, 0.02579702, 0.02453773, ..., 0.03602878, 0.03394552,\n",
      "       0.0389076 ], dtype=float32), array([0.02954297, 0.03284819, 0.02930232, ..., 0.04787353, 0.05022185,\n",
      "       0.04799343], dtype=float32), array([0.02708384, 0.02898625, 0.02662156, ..., 0.04171355, 0.04072944,\n",
      "       0.04379524], dtype=float32)]}}, 'DER': {'0D': {'predictive': array([0.02864474, 0.0435985 , 0.02862994, ..., 0.0389538 , 0.04148561,\n",
      "       0.04038005], dtype=float32), 'feature': array([0.04699073, 0.04795371, 0.04068378, ..., 0.04637714, 0.04537285,\n",
      "       0.0461653 ], dtype=float32)}, '2D': {'predictive': array([0.04532349, 0.0467452 , 0.04470569, ..., 0.04873373, 0.04735764,\n",
      "       0.04925903], dtype=float32), 'feature': array([0.02539387, 0.026505  , 0.02495383, ..., 0.04026399, 0.03869948,\n",
      "       0.04047922], dtype=float32)}}}, 'high': {'DE': {'0D': {'predictive': [array([0.0930673 , 0.06638714, 0.10410436, ..., 0.07479335, 0.0948856 ,\n",
      "       0.06957744], dtype=float32), array([0.08863991, 0.0657451 , 0.09845598, ..., 0.06711736, 0.09192337,\n",
      "       0.06480754], dtype=float32), array([0.08757786, 0.064126  , 0.09586323, ..., 0.07419823, 0.08981287,\n",
      "       0.07048802], dtype=float32), array([0.09329183, 0.06539062, 0.10110732, ..., 0.06123518, 0.08520719,\n",
      "       0.06110872], dtype=float32), array([0.09767479, 0.06714072, 0.10423027, ..., 0.0750728 , 0.09479693,\n",
      "       0.07073281], dtype=float32), array([0.09083864, 0.06188665, 0.10076329, ..., 0.0665691 , 0.09108098,\n",
      "       0.06230807], dtype=float32), array([0.09385408, 0.06755079, 0.10058987, ..., 0.06660571, 0.09225217,\n",
      "       0.06389713], dtype=float32), array([0.09257314, 0.06372629, 0.09930712, ..., 0.07237435, 0.09091856,\n",
      "       0.0689604 ], dtype=float32), array([0.09386807, 0.06047967, 0.09806158, ..., 0.07617669, 0.09687149,\n",
      "       0.07166396], dtype=float32), array([0.09310744, 0.06613403, 0.10072859, ..., 0.07041713, 0.09168331,\n",
      "       0.07072436], dtype=float32)], 'feature': [array([0.07449621, 0.088962  , 0.07529597, ..., 0.09195641, 0.06150603,\n",
      "       0.08659457], dtype=float32), array([0.07874567, 0.092492  , 0.07999807, ..., 0.09544126, 0.06213867,\n",
      "       0.09160677], dtype=float32), array([0.07817023, 0.09740989, 0.07949487, ..., 0.09515934, 0.0691748 ,\n",
      "       0.09066448], dtype=float32), array([0.07489816, 0.09072052, 0.08052356, ..., 0.08837562, 0.06618287,\n",
      "       0.0841305 ], dtype=float32), array([0.07432076, 0.09116031, 0.07825984, ..., 0.09211765, 0.07031375,\n",
      "       0.08748414], dtype=float32), array([0.07514355, 0.08926119, 0.07753117, ..., 0.09764069, 0.07179757,\n",
      "       0.0867829 ], dtype=float32), array([0.07551179, 0.09291856, 0.07555156, ..., 0.09725639, 0.07558719,\n",
      "       0.09282896], dtype=float32), array([0.07796865, 0.09161795, 0.07867014, ..., 0.09230145, 0.06534881,\n",
      "       0.08811326], dtype=float32), array([0.07856869, 0.09215771, 0.07840519, ..., 0.09095426, 0.06329733,\n",
      "       0.08443222], dtype=float32), array([0.07843285, 0.09431029, 0.08083614, ..., 0.09698475, 0.07106264,\n",
      "       0.0914464 ], dtype=float32)]}, '2D': {'predictive': [array([0.10581729, 0.09210659, 0.09747739, ..., 0.09833564, 0.11745816,\n",
      "       0.10780466], dtype=float32), array([0.09256625, 0.07722413, 0.08252688, ..., 0.07433549, 0.09464774,\n",
      "       0.08465558], dtype=float32), array([0.10014416, 0.08772044, 0.09829827, ..., 0.08117112, 0.10103751,\n",
      "       0.0872451 ], dtype=float32), array([0.09575068, 0.07832657, 0.08686419, ..., 0.0778218 , 0.09582611,\n",
      "       0.08944524], dtype=float32), array([0.106871  , 0.08677518, 0.09418721, ..., 0.08583105, 0.11715378,\n",
      "       0.09739219], dtype=float32), array([0.10040644, 0.08170595, 0.09028696, ..., 0.08528963, 0.10582665,\n",
      "       0.09232701], dtype=float32), array([0.09577265, 0.07933597, 0.08743144, ..., 0.08030102, 0.10892105,\n",
      "       0.09405839], dtype=float32), array([0.09157817, 0.07924557, 0.080524  , ..., 0.08008958, 0.09818754,\n",
      "       0.08856084], dtype=float32), array([0.10329171, 0.0836046 , 0.09390089, ..., 0.0911397 , 0.10293368,\n",
      "       0.09391037], dtype=float32), array([0.09598438, 0.08005073, 0.08794715, ..., 0.0836485 , 0.10936299,\n",
      "       0.09562998], dtype=float32)], 'feature': [array([0.04807015, 0.05125957, 0.0441457 , ..., 0.06546387, 0.06522512,\n",
      "       0.06941967], dtype=float32), array([0.05072187, 0.05806559, 0.04774181, ..., 0.07977483, 0.07986014,\n",
      "       0.08600222], dtype=float32), array([0.05023019, 0.05511292, 0.042162  , ..., 0.07636168, 0.07066303,\n",
      "       0.08467886], dtype=float32), array([0.04593337, 0.05333942, 0.04131125, ..., 0.07177132, 0.07271729,\n",
      "       0.07381272], dtype=float32), array([0.04972599, 0.05411399, 0.04679431, ..., 0.07048349, 0.06783428,\n",
      "       0.07491116], dtype=float32), array([0.04587637, 0.05177809, 0.0415261 , ..., 0.07326594, 0.06734011,\n",
      "       0.07931866], dtype=float32), array([0.04710044, 0.05510196, 0.03877275, ..., 0.07166824, 0.06801183,\n",
      "       0.07311269], dtype=float32), array([0.05057052, 0.05797824, 0.0477282 , ..., 0.07983498, 0.07594524,\n",
      "       0.086052  ], dtype=float32), array([0.04676608, 0.04924922, 0.04406746, ..., 0.06720065, 0.06288997,\n",
      "       0.07229595], dtype=float32), array([0.04573241, 0.05146042, 0.04135597, ..., 0.06326679, 0.05475409,\n",
      "       0.06837624], dtype=float32)]}}, 'DER': {'0D': {'predictive': array([0.09094831, 0.0629371 , 0.09452813, ..., 0.06716414, 0.08063954,\n",
      "       0.06665199], dtype=float32), 'feature': array([0.06667694, 0.08256149, 0.06858577, ..., 0.08373443, 0.05764031,\n",
      "       0.08139787], dtype=float32)}, '2D': {'predictive': array([0.08750986, 0.09371389, 0.09072596, ..., 0.09033608, 0.09268706,\n",
      "       0.09578887], dtype=float32), 'feature': array([0.0507179 , 0.05726055, 0.04548245, ..., 0.06703238, 0.06492739,\n",
      "       0.07051057], dtype=float32)}}}}\n"
     ]
    }
   ],
   "source": [
    "print('mega dict', mega_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cafd8a-fae6-44ca-8677-d6e3bf889a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# suppress seaborn/pandas specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Example setup, use your actual data/model outputs\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(1, len(model_type) * len(noise_list), figsize=(20, 3.5))\n",
    "axes = axes.flatten()\n",
    "index = 0\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "palette = sns.color_palette(\"Paired\", n_colors=len(data_dim_list) * len(inject_type_list))\n",
    "\n",
    "# Define x-axis limits for each noise level\n",
    "x_limits = {\n",
    "    \"low\": (0, 0.05),\n",
    "    \"medium\": (0, 0.1),\n",
    "    \"high\": (0, 0.12)\n",
    "}\n",
    "\n",
    "for n, noise in enumerate(noise_list):\n",
    "    for m, model in enumerate(model_type):\n",
    "        ax = axes[index]\n",
    "        \n",
    "        y_offset = 0  # Initialize a consistent y_offset\n",
    "        kde_max = 0  # Track the maximum y-value across all KDE plots\n",
    "        \n",
    "        # Collect KDE data to plot\n",
    "        kde_data = []\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "                # Generate or load aleatoric uncertainty data (replace with your own logic)\n",
    "                u_al_data = mega_dict[noise][model][dim][inject_type]\n",
    "                \n",
    "                \n",
    "                # Stack the DEs\n",
    "                if model == \"DE\":\n",
    "                    combined_array = np.concatenate(u_al_data)\n",
    "                elif model == \"DER\":\n",
    "                    combined_array = u_al_data\n",
    "                \n",
    "                # Store KDE data\n",
    "                kde_data.append((combined_array, palette[j*len(inject_type_list)+i], f\"{new_title_lookup[inject_type]} - {dim}\"))\n",
    "        \n",
    "        # Plot KDEs in reverse order\n",
    "        for combined_array, color, label in reversed(kde_data):\n",
    "            '''\n",
    "            kde = sns.kdeplot(combined_array, fill=True, bw_adjust=0.5, alpha=0.75, ax=ax,\n",
    "                              clip_on=False, color=color, label=label)\n",
    "\n",
    "            # Retrieve the KDE data\n",
    "            x = kde.lines[0].get_data()[0]\n",
    "            y = kde.lines[0].get_data()[1]\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Clear the previous KDE plot\n",
    "            ax.clear()\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_normalized, color='blue', alpha=0.75)\n",
    "            ax.plot(x, y_normalized, color='blue', label='Normalized KDE')\n",
    "            '''\n",
    "            # Compute KDE\n",
    "            kde = gaussian_kde(combined_array, bw_method=0.1)  # Adjust bw_method as needed\n",
    "            \n",
    "            # Define range of x values\n",
    "            x = np.linspace(min(combined_array), max(combined_array), 1000)\n",
    "            \n",
    "            # Evaluate KDE over x values\n",
    "            y = kde(x)\n",
    "            \n",
    "            # Normalize the KDE data\n",
    "            max_height = 0.5  # Desired maximum height\n",
    "            y_normalized = (y / y.max()) * max_height\n",
    "            \n",
    "            # Plot the normalized KDE\n",
    "            ax.fill_between(x, y_offset, y_normalized + y_offset, color=color, alpha=0.75)\n",
    "            ax.plot(x, y_normalized + y_offset, color=color, label=label)\n",
    "            \n",
    "            '''\n",
    "            # Find the maximum y-value and adjust offsets\n",
    "            if kde.collections:\n",
    "                paths = kde.collections[-1].get_paths()\n",
    "                for path in paths:\n",
    "                    vertices = path.vertices\n",
    "                    vertices[:, 1] += y_offset  # Offset the y-values of the vertices\n",
    "                    kde_max = vertices[:, 1].max() / 1.5\n",
    "            '''\n",
    "            ax.scatter(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                color='black', edgecolor='black', zorder=100)\n",
    "            \n",
    "            ax.errorbar(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                xerr = 3*np.std(combined_array),\n",
    "                color='grey', capsize=5)\n",
    "            ax.errorbar(\n",
    "                np.mean(combined_array), y_offset + 0.1,\n",
    "                xerr = np.std(combined_array),\n",
    "                color='black', capsize=5)\n",
    "            y_offset += 0.25\n",
    "\n",
    "        # Set title and limits\n",
    "        #ax.set_title(f'{model} - {noise} noise')\n",
    "        ax.set_yticks([])  # Hide y-ticks\n",
    "        ax.set_ylim(0, y_offset+0.25)  # Adjust y-limits based on the max y_offset\n",
    "        \n",
    "        # Set x-axis limits after plotting\n",
    "        ax.set_xlim(x_limits[noise])\n",
    "\n",
    "        # Add vertical line indicating sigma_y for reference\n",
    "        if noise == \"low\":\n",
    "            ax.axvline(x=0.01, color='grey', ls='--')\n",
    "        elif noise == \"medium\":\n",
    "            ax.axvline(x=0.05, color='grey', ls='--')\n",
    "        elif noise == \"high\":\n",
    "            ax.axvline(x=0.10, color='grey', ls='--')\n",
    "        \n",
    "        # Only add the legend on the first subplot\n",
    "        if index == 0:\n",
    "            ax.legend(loc='upper right')\n",
    "        else:\n",
    "            ax.legend().remove()  # Remove the legend from all other subplots\n",
    "        ax.set_yticklabels([])\n",
    "        index += 1\n",
    "\n",
    "axes[0].set_xlim([0, 0.06])\n",
    "axes[1].set_xlim([0, 0.03])\n",
    "axes[2].set_xlim([0, 0.09])\n",
    "axes[3].set_xlim([0.01, 0.07])\n",
    "axes[4].set_xlim([0.01, 0.13])\n",
    "axes[5].set_xlim([0.01, 0.13])\n",
    "\n",
    "\n",
    "#axes[0].set_xlabel(r'$\\sigma_{al}$')\n",
    "plt.subplots_adjust(wspace=-0.5, hspace=-3)\n",
    "plt.tick_params(axis='x', which='major', labelsize=14)\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../../../Desktop/sigma_in_sigma_out_ridgeplot_ensemble_{n_models}_uniform.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c64b0-5be3-4c03-85c6-5cea632b01a5",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# suppress seaborn/pandas specific warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "# Example setup, use your actual data/model outputs\n",
    "noise_list = [\"low\", \"medium\", \"high\"]\n",
    "model_type = [\"DE\", \"DER\"]\n",
    "inject_type_list = [\"predictive\", \"feature\"]\n",
    "data_dim_list = [\"0D\", \"2D\"]\n",
    "\n",
    "# Set up figure and axes\n",
    "fig, axes = plt.subplots(1, len(model_type) * len(noise_list), figsize=(20, 3.5))\n",
    "axes = axes.flatten()\n",
    "index = 0\n",
    "\n",
    "sigma_y_lookup = {'low': 0.01, 'medium': 0.05, 'high': 0.10}\n",
    "palette = sns.color_palette(\"Paired\", n_colors=len(data_dim_list) * len(inject_type_list))\n",
    "\n",
    "# Define x-axis limits for each noise level\n",
    "x_limits = {\n",
    "    \"low\": (0, 0.05),\n",
    "    \"medium\": (0, 0.1),\n",
    "    \"high\": (0, 0.12)\n",
    "}\n",
    "\n",
    "for n, noise in enumerate(noise_list):\n",
    "    for m, model in enumerate(model_type):\n",
    "        ax = axes[index]\n",
    "        \n",
    "        y_offset = 0  # Initialize a consistent y_offset\n",
    "        kde_max = 0  # Track the maximum y-value across all KDE plots\n",
    "        \n",
    "        # Collect KDE data to plot\n",
    "        kde_data = []\n",
    "        for j, dim in enumerate(data_dim_list):\n",
    "            for i, inject_type in enumerate(inject_type_list):\n",
    "                # Generate or load aleatoric uncertainty data (replace with your own logic)\n",
    "                u_al_data = mega_dict[noise][model][dim][inject_type]\n",
    "                \n",
    "                \n",
    "                # Stack the DEs\n",
    "                if model == \"DE\":\n",
    "                    combined_array = np.concatenate(u_al_data)\n",
    "                elif model == \"DER\":\n",
    "                    combined_array = u_al_data\n",
    "                \n",
    "                # Store KDE data\n",
    "                kde_data.append((combined_array, palette[j*len(inject_type_list)+i], f\"{inject_type} - {dim}\"))\n",
    "        \n",
    "        # Plot KDEs in reverse order\n",
    "        for combined_array, color, label in reversed(kde_data):\n",
    "            kde = sns.kdeplot(combined_array, fill=True, bw_adjust=0.5, alpha=0.75, ax=ax,\n",
    "                              clip_on=True, color=color, label=label, common_norm=1)\n",
    "            \n",
    "            # Find the maximum y-value and adjust offsets\n",
    "            if kde.collections:\n",
    "                paths = kde.collections[-1].get_paths()\n",
    "                for path in paths:\n",
    "                    vertices = path.vertices\n",
    "                    vertices[:, 1] += y_offset  # Offset the y-values of the vertices\n",
    "                    kde_max = vertices[:, 1].max() / 1.5\n",
    "                    ax.scatter(\n",
    "                        np.mean(combined_array), vertices[:, 1].mean(),\n",
    "                        color=color, edgecolor='white', zorder=100)\n",
    "                    \n",
    "                    ax.errorbar(\n",
    "                        np.mean(combined_array), vertices[:, 1].mean(),\n",
    "                        xerr = 3*np.std(combined_array),\n",
    "                        color='grey', capsize=5)\n",
    "                    ax.errorbar(\n",
    "                        np.mean(combined_array), vertices[:, 1].mean(),\n",
    "                        xerr = np.std(combined_array),\n",
    "                        color='black', capsize=5)\n",
    "                y_offset += kde_max\n",
    "\n",
    "        # Set title and limits\n",
    "        ax.set_title(f'{model} - {noise} noise')\n",
    "        ax.set_yticks([])  # Hide y-ticks\n",
    "        ax.set_ylim(0, y_offset)  # Adjust y-limits based on the max y_offset\n",
    "        \n",
    "        # Set x-axis limits after plotting\n",
    "        ax.set_xlim(x_limits[noise])\n",
    "\n",
    "        # Add vertical line indicating sigma_y for reference\n",
    "        if noise == \"low\":\n",
    "            ax.axvline(x=0.01, color='grey', ls='--')\n",
    "        elif noise == \"medium\":\n",
    "            ax.axvline(x=0.05, color='grey', ls='--')\n",
    "        elif noise == \"high\":\n",
    "            ax.axvline(x=0.10, color='grey', ls='--')\n",
    "        \n",
    "        # Only add the legend on the first subplot\n",
    "        if index == 0:\n",
    "            ax.legend(loc='upper right')\n",
    "        else:\n",
    "            ax.legend().remove()  # Remove the legend from all other subplots\n",
    "        ax.set_yticklabels([])\n",
    "        index += 1\n",
    "\n",
    "axes[0].set_xlim([0, 0.06])\n",
    "axes[1].set_xlim([0, 0.03])\n",
    "axes[2].set_xlim([0, 0.09])\n",
    "axes[3].set_xlim([0, 0.09])\n",
    "axes[4].set_xlim([0, 0.13])\n",
    "axes[5].set_xlim([0, 0.13])\n",
    "\n",
    "axes[0].set_xlabel(r'$\\sigma_{al}$')\n",
    "plt.subplots_adjust(wspace=-0.5, hspace=-0.5)\n",
    "\n",
    "# Adjust layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../../../Desktop/sigma_in_sigma_out_ridgeplot_ensemble_{n_models}_uniform.png', dpi=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
