@phdthesis{brando2022thesis,
  author       = {A. Brando},
  title        = {Aleatoric uncertainty modelling in regression problems using deep learning},
  school       = {Universitat de Barcelona},
  year         = {2022}
}

@ARTICLE{Tran2019arXiv191210066T,
       author = {{Tran}, Kevin and {Neiswanger}, Willie and {Yoon}, Junwoong and {Zhang}, Qingyang and {Xing}, Eric and {Ulissi}, Zachary W.},
        title = "{Methods for comparing uncertainty quantifications for material property predictions}",
      journal = {arXiv e-prints},
     keywords = {Condensed Matter - Materials Science, Physics - Computational Physics},
         year = 2019,
        month = dec,
          eid = {arXiv:1912.10066},
        pages = {arXiv:1912.10066},
          doi = {10.48550/arXiv.1912.10066},
archivePrefix = {arXiv},
       eprint = {1912.10066},
 primaryClass = {cond-mat.mtrl-sci},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191210066T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Gal2022NatRP...4..573G,
       author = {{Gal}, Yarin and {Koumoutsakos}, Petros and {Lanusse}, Francois and {Louppe}, Gilles and {Papadimitriou}, Costas},
        title = "{Bayesian uncertainty quantification for machine-learned models in physics}",
      journal = {Nature Reviews Physics},
         year = 2022,
        month = aug,
       volume = {4},
       number = {9},
        pages = {573-577},
          doi = {10.1038/s42254-022-00498-4},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022NatRP...4..573G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@ARTICLE{GalMCDropout2015arXiv150602142G,
       author = {{Gal}, Yarin and {Ghahramani}, Zoubin},
        title = "{Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2015,
        month = jun,
          eid = {arXiv:1506.02142},
        pages = {arXiv:1506.02142},
          doi = {10.48550/arXiv.1506.02142},
archivePrefix = {arXiv},
       eprint = {1506.02142},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150602142G},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Caldeira2020arXiv200410710C,
       author = {{Caldeira}, Jo{\~a}o and {Nord}, Brian},
        title = "{Deeply Uncertain: Comparing Methods of Uncertainty Quantification in Deep Learning Algorithms}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
         year = 2020,
        month = apr,
          eid = {arXiv:2004.10710},
        pages = {arXiv:2004.10710},
          doi = {10.48550/arXiv.2004.10710},
archivePrefix = {arXiv},
       eprint = {2004.10710},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200410710C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{Yang2023,
author = {Yang, Chu-I and Li, Yi-Pei},
year = {2023},
month = {02},
pages = {},
title = {Explainable uncertainty quantifications for deep learning-based molecular property prediction},
volume = {15},
journal = {Journal of Cheminformatics},
doi = {10.1186/s13321-023-00682-3}
}

@ARTICLE{Seitzer2022arXiv220309168S,
       author = {{Seitzer}, Maximilian and {Tavakoli}, Arash and {Antic}, Dimitrije and {Martius}, Georg},
        title = "{On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2022,
        month = mar,
          eid = {arXiv:2203.09168},
        pages = {arXiv:2203.09168},
          doi = {10.48550/arXiv.2203.09168},
archivePrefix = {arXiv},
       eprint = {2203.09168},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220309168S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@ARTICLE{Kendall2017arXiv170304977K,
       author = {{Kendall}, Alex and {Gal}, Yarin},
        title = "{What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computer Vision and Pattern Recognition},
         year = 2017,
        month = mar,
          eid = {arXiv:1703.04977},
        pages = {arXiv:1703.04977},
          doi = {10.48550/arXiv.1703.04977},
archivePrefix = {arXiv},
       eprint = {1703.04977},
 primaryClass = {cs.CV},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170304977K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@INPROCEEDINGS{Nix374138,
  author={Nix, D.A. and Weigend, A.S.},
  booktitle={Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN'94)}, 
  title={Estimating the mean and variance of the target probability distribution}, 
  year={1994},
  volume={1},
  number={},
  pages={55-60 vol.1},
  keywords={Probability distribution;Noise level;Feedforward systems;Computer science;Cognitive science;Computer errors;Measurement uncertainty;Cost function;Equations;Error correction},
  doi={10.1109/ICNN.1994.374138}}

@ARTICLE{Lakshminarayanan2016arXiv161201474L,
       author = {{Lakshminarayanan}, Balaji and {Pritzel}, Alexander and {Blundell}, Charles},
        title = "{Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2016,
        month = dec,
          eid = {arXiv:1612.01474},
        pages = {arXiv:1612.01474},
          doi = {10.48550/arXiv.1612.01474},
archivePrefix = {arXiv},
       eprint = {1612.01474},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2016arXiv161201474L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{brando2023standardizing,
  title={Standardizing the probabilistic sources of uncertainty for the sake of safety deep learning},
  author={Brando, Axel and Serra, Isabel and Mezzetti, Enrico and Cazorla Almeida, Francisco Javier and Abella Ferrer, Jaume},
  booktitle={Proceedings of the Workshop on Artificial Intelligence Safety 2023 (SafeAI 2023) co-located with the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023): Washington DC, USA, February 13-14, 2023.},
  volume={3381},
  year={2023},
  organization={CEUR Workshop Proceedings}
}

@ARTICLE{Seitzer2022,
       author = {{Seitzer}, Maximilian and {Tavakoli}, Arash and {Antic}, Dimitrije and {Martius}, Georg},
        title = "{On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2022,
        month = mar,
          eid = {arXiv:2203.09168},
        pages = {arXiv:2203.09168},
          doi = {10.48550/arXiv.2203.09168},
archivePrefix = {arXiv},
       eprint = {2203.09168},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220309168S},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{Meinert2022DER,
       author = {{Meinert}, Nis and {Gawlikowski}, Jakob and {Lavin}, Alexander},
        title = "{The Unreasonable Effectiveness of Deep Evidential Regression}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = 2022,
        month = may,
          eid = {arXiv:2205.10060},
        pages = {arXiv:2205.10060},
          doi = {10.48550/arXiv.2205.10060},
archivePrefix = {arXiv},
       eprint = {2205.10060},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv220510060M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{Amini2019DER,
       author = {{Amini}, Alexander and {Schwarting}, Wilko and {Soleimany}, Ava and {Rus}, Daniela},
        title = "{Deep Evidential Regression}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = 2019,
        month = oct,
          eid = {arXiv:1910.02600},
        pages = {arXiv:1910.02600},
          doi = {10.48550/arXiv.1910.02600},
archivePrefix = {arXiv},
       eprint = {1910.02600},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv191002600A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{PS2017,
author = {Nicholas G. Polson and Vadim Sokolov},
title = {{Deep Learning: A Bayesian Perspective}},
volume = {12},
journal = {Bayesian Analysis},
number = {4},
publisher = {International Society for Bayesian Analysis},
pages = {1275 -- 1304},
keywords = {Artificial intelligence, Bayesian hierarchical models, deep learning, LSTM models, machine learning, pattern matching, prediction, TensorFlow},
year = {2017},
doi = {10.1214/17-BA1082},
URL = {https://doi.org/10.1214/17-BA1082}
}

@INPROCEEDINGS{LV2000,
  author={Lampinen, Jouko and Vehtari, Aki},
  booktitle={2000 10th European Signal Processing Conference}, 
  title={Bayesian techniques for neural networks â€” Review and case studies}, 
  year={2000},
  volume={},
  number={},
  pages={1-8},
  keywords={Bayes methods;Noise;Computational modeling;Data models;Complexity theory;Predictive models;Neural networks},
  doi={}}

@article{T2004,
author = {D. M. Titterington},
title = {{Bayesian Methods for Neural Networks and Related Models}},
volume = {19},
journal = {Statistical Science},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {128 -- 139},
keywords = {Bayesian methods, Bayesian model choice, feed-forward neural network, Graphical model, Laplace approximation, machine learning, Markov chain Monte Carlo, variational approximation},
year = {2004},
doi = {10.1214/088342304000000099},
URL = {https://doi.org/10.1214/088342304000000099}
}

@book{ZZ2012, 
author = {Zhou, Zhi-Hua}, title = {Ensemble Methods: Foundations and Algorithms}, year = {2012}, isbn = {1439830037}, publisher = {Chapman \& Hall/CRC}, edition = {1st}, abstract = {An up-to-date, self-contained introduction to a state-of-the-art machine learning approach, Ensemble Methods: Foundations and Algorithms shows how these accurate methods are used in real-world tasks. It gives you the necessary groundwork to carry out further research in this evolving field. After presenting background and terminology, the book covers the main algorithms and theories, including Boosting, Bagging, Random Forest, averaging and voting schemes, the Stacking method, mixture of experts, and diversity measures. It also discusses multiclass extension, noise tolerance, error-ambiguity and bias-variance decompositions, and recent progress in information theoretic diversity. Moving on to more advanced topics, the author explains how to achieve better performance through ensemble pruning and how to generate better clustering results by combining multiple clusterings. In addition, he describes developments of ensemble methods in semi-supervised learning, active learning, cost-sensitive learning, class-imbalance learning, and comprehensibility enhancement.} }

